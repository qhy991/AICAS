{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b27a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c46d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数组中元素拼接组合\n",
    "def array_to_string(array, elem_bit):\n",
    "    val = 0\n",
    "    for i in range(len(array)):\n",
    "        tmp = array[i]\n",
    "        tmp2 = tmp\n",
    "        \n",
    "        if tmp < 0:\n",
    "            tmp2 = 2**(elem_bit) + tmp\n",
    "            \n",
    "        tmp2 = int(tmp2)\n",
    "        tmp3 = tmp2 * 2**(elem_bit*i)\n",
    "        val = val + tmp3\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d278d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamProcess:\n",
    "    def __init__(self, name, config, w, bias, w_bit, in_bit, out_bit, bias_bit, pe, simd, r_shift):\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.w = w\n",
    "        self.bias = bias\n",
    "        self.w_bit = w_bit\n",
    "        self.in_bit = in_bit\n",
    "        self.out_bit = out_bit\n",
    "        self.bias_bit = bias_bit\n",
    "        self.pe = pe\n",
    "        self.simd = simd\n",
    "        self.r_shift = r_shift\n",
    "    \n",
    "    # 将矩阵整理成所需的存储样式\n",
    "    # 转化为pe * tiles矩阵\n",
    "    def w_to_hls_array(self, w):\n",
    "        # print(#\"w shape: \", w.shape)\n",
    "        assert w.shape[0] % self.pe == 0, 'out_ch mod pe must 0'\n",
    "        # w 矩阵宽 k*K*in_ch\n",
    "        h = w.shape[1]\n",
    "        # res0 size = out_ch, k*K*in_ch // simd + (0 or 1)\n",
    "        res0 = [[0 for i in range(h // self.simd)] for j in range(w.shape[0])]\n",
    "        for out_ch in range(w.shape[0]):\n",
    "            for i in range(h // self.simd):\n",
    "                arr = w[out_ch][i*self.simd:(i+1)*self.simd]\n",
    "                res0[out_ch][i] = array_to_string(arr, self.w_bit)\n",
    "        \n",
    "        # 处理不够整除部分\n",
    "        if h % self.simd != 0:\n",
    "            print('h mod simd != 0')\n",
    "            for out_ch in range(w.shape[0]):\n",
    "                arr = w[out_ch][h // self.simd * self.simd]\n",
    "                res0[out_ch].append(array_to_string(arr, self.w_bit))\n",
    "                \n",
    "        \n",
    "        tiles = len(res0[0]) * (len(res0) // self.pe)\n",
    "        self.w_tiles = tiles\n",
    "        # print('tiles', tiles)\n",
    "        res = [[0 for i in range(tiles)] for i in range(self.pe)]\n",
    "        \n",
    "        tiles_cnt = 0\n",
    "        for i in range(len(res0) // self.pe):\n",
    "            for j in range(len(res0[0])):\n",
    "                for pe_cnt in range(self.pe):\n",
    "                    res[pe_cnt][tiles_cnt] = res0[i * self.pe + pe_cnt][j]\n",
    "                tiles_cnt += 1\n",
    "        return res\n",
    "    \n",
    "    def bias_to_hls_array(self, bias):\n",
    "        bias = bias.reshape(-1, self.pe)\n",
    "        bias = bias.T\n",
    "        \n",
    "        return bias\n",
    "    \n",
    "    def conv(self):\n",
    "        w = self.w\n",
    "        bias = self.bias\n",
    "        # w是二维矩阵形式\n",
    "        conv_w = w.transpose(0, 2, 3, 1)\n",
    "        # 处理为二维矩阵\n",
    "        conv_w = conv_w.reshape(conv_w.shape[0], -1)\n",
    "        # print(w.shape)\n",
    "        # 先把w处理为每个元素位宽都是simd * w_bit形式\n",
    "        conv_w = self.w_to_hls_array(conv_w)\n",
    "        \n",
    "        bias = self.bias_to_hls_array(bias)\n",
    "        \n",
    "        self.hls_w = conv_w\n",
    "        self.hls_bias = bias\n",
    "        \n",
    "        return conv_w, bias\n",
    "    \n",
    "    def w_to_hls_init_str(self, w) -> str:\n",
    "        w_mem_type = \"const ap_uint<\"+str(self.w_bit * self.simd)+\">\"\n",
    "        \n",
    "        res = '//'  + self.name + '_w\\n'\n",
    "        res += '//PEs = %d, SIMD = %d\\n' % (self.pe, self.simd)\n",
    "        res += '//bit = %d\\n' % self.w_bit\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_w')\n",
    "        res += '[%d][%d] = {\\n' % (len(w), len(w[0]))\n",
    "        \n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", w))\n",
    "        res += '};\\n'\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def bias_to_hls_init_str(self, bias) -> str:\n",
    "        bias_bit_width = self.bias_bit\n",
    "        \n",
    "        w_mem_type = \"const ap_int<\"+str(self.bias_bit)+\">\"\n",
    "        \n",
    "        res = '// bias\\n'\n",
    "        res += '//'  + self.name + '_bias\\n'\n",
    "        res += '//w_bit = %d\\n' % bias_bit_width\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_bias')\n",
    "        res += '[%d][%d] = {\\n' % (len(bias), len(bias[0]))\n",
    "        \n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", bias))\n",
    "        res += '};\\n'\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def layer_param_to_init_str(self, w, bias) -> str:\n",
    "        res = self.w_to_hls_init_str(w)\n",
    "        res += self.bias_to_hls_init_str(bias)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def add_a_config_str(self, config_name, value) -> str:\n",
    "        res = '#define %s_%s %d \\n' % (self.name.upper(), config_name.upper(), value)\n",
    "        return res\n",
    "\n",
    "    def conv_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "        res += self.add_a_config_str('K', self.config['k'])\n",
    "        res += self.add_a_config_str('S', self.config['s'])\n",
    "        res += self.add_a_config_str('P', self.config['p'])\n",
    "        res += self.add_a_config_str('IFM_CH', self.config['in_shape'][0])\n",
    "        res += self.add_a_config_str('IFM_ROW', self.config['in_shape'][1])\n",
    "        res += self.add_a_config_str('IFM_COL', self.config['in_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('OFM_CH', self.config['out_shape'][0])\n",
    "        res += self.add_a_config_str('OFM_ROW', self.config['out_shape'][1])\n",
    "        res += self.add_a_config_str('OFM_COL', self.config['out_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        res += self.add_a_config_str('BIAS_BIT', self.bias_bit)\n",
    "\n",
    "        res += self.add_a_config_str('R_SHIFT', self.r_shift)\n",
    "\n",
    "        res += '\\n'\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8977072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis(code, pe, simd, r_shift):\n",
    "    config_dic = {}\n",
    "    \n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    #print(channel_num)\n",
    "    layer_num = code[-5:]\n",
    "    #print(layer_num)\n",
    "    map_pool = {0:True,1:True,2:False}\n",
    "    pools = [map_pool[key] for key in code[10:16]] \n",
    "    #print(pools)\n",
    "    shape_size = [32,32,16,8,4,2]\n",
    "    \n",
    "    # initial channel\n",
    "    in_channel = 3\n",
    "    out_channel = int(channel_num[0])\n",
    "    \n",
    "    param_num = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        for j in range(layer_num[i]):\n",
    "            name = \"conv_\"+str(i)+\"_\"+str(j)\n",
    "            # initial config\n",
    "            config = {'k':3, 's':1, 'p':1, 'in_shape':(3, 32, 32), 'out_shape':(8, 32, 32)}\n",
    "            \n",
    "            # modify 'in_shape'\n",
    "            config['in_shape'] = (in_channel, shape_size[i], shape_size[i])\n",
    "            \n",
    "            if (j == layer_num[i]-1):\n",
    "                if (not pools[i]) :\n",
    "                    # no pooling \n",
    "                    config['s'] = 2\n",
    "                    config['out_shape'] = (out_channel, shape_size[i+1], shape_size[i+1])\n",
    "                    config['simd'] = simd[param_num]\n",
    "                    config['pe'] = pe[param_num]\n",
    "                    config['r_shift'] = r_shift[param_num]\n",
    "                    config_dic[name]=config\n",
    "\n",
    "                else :\n",
    "                    # pooling\n",
    "                    config['s'] = 1\n",
    "                    config['out_shape'] = (out_channel, shape_size[i], shape_size[i])\n",
    "                    config['simd'] = simd[param_num]\n",
    "                    config['pe'] = pe[param_num]\n",
    "                    config['r_shift'] = r_shift[param_num]\n",
    "                    config_dic[name]=config\n",
    "                    \n",
    "                    pool_name = \"pool_\"+str(i)\n",
    "                    config_dic[pool_name]={'k':2, 's':1, 'p':0}\n",
    "\n",
    "                # renew channel\n",
    "                if i < 4 :\n",
    "                    in_channel = out_channel\n",
    "                    out_channel = int(channel_num[i+1])\n",
    "                \n",
    "                param_num += 1\n",
    "                \n",
    "            else :\n",
    "                config['s'] = 1\n",
    "                config['out_shape'] = (out_channel, shape_size[i], shape_size[i])\n",
    "                config['simd'] = simd[param_num]\n",
    "                config['pe'] = pe[param_num]\n",
    "                config['r_shift'] = r_shift[param_num]\n",
    "                config_dic[name]=config\n",
    "\n",
    "                # renew channel\n",
    "                in_channel = out_channel\n",
    "                out_channel = int(channel_num[i])\n",
    "                \n",
    "                param_num += 1\n",
    "            \n",
    "    return config_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58441d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_param(code, config_dic):\n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    layer_num = code[-5:]\n",
    "    \n",
    "    conv = \"\"\n",
    "    conv_config = \"\"\n",
    "    \n",
    "    for i in range(5):\n",
    "        for j in range(layer_num[i]):\n",
    "            name = \"conv_\"+str(i)+\"_\"+str(j)\n",
    "            config = config_dic[name]\n",
    "            \n",
    "            weight_shape = (int(config['out_shape'][0]), int(config['in_shape'][0]), 3, 3)\n",
    "            weight = np.random.randint(-26, 256, size=weight_shape)\n",
    "            #print(weight.shape)\n",
    "            \n",
    "            bias_shape = (int(config['out_shape'][0]))\n",
    "            bias = np.random.randint(-256, 255, size=bias_shape)\n",
    "            \n",
    "            processer = ParamProcess(\n",
    "                name=name, \n",
    "                config=config,\n",
    "                w=weight, bias=bias, \n",
    "                w_bit=8, in_bit=8, out_bit=8, bias_bit=32, \n",
    "                pe=config['pe'], simd=config['simd'], r_shift=config['r_shift'])\n",
    "            \n",
    "            w_str, b_str = processer.conv()\n",
    "            conv_str = processer.layer_param_to_init_str(w_str, b_str)\n",
    "            conv_config_str = processer.conv_config_str()\n",
    "            \n",
    "            conv += conv_str\n",
    "            conv_config += conv_config_str\n",
    "    \n",
    "    return conv, conv_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d45b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [1.0, 1.0, 0.25, 0.375, 0.75, 0, 1, 0, 1, 1, 0, 1, 0, 1, 2, 0, 1, 3, 2, 5, 1]\n",
    "pe = [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
    "simd = [3, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
    "r_shift = [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
    "\n",
    "config = model_analysis(code, pe, simd, r_shift)\n",
    "conv_param, conv_config = config_param(code, config)\n",
    "\n",
    "hls_param_file = open('param.h', 'w')\n",
    "hls_config_file = open('config.h', 'w')\n",
    "\n",
    "hls_param_file.write(conv_param)\n",
    "hls_config_file.write(conv_config)\n",
    "\n",
    "hls_param_file.close()\n",
    "hls_config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c7c82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c702fa59d8122797944f957dba7be4f979da7d1929b3cf04b128c443ec5b9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
