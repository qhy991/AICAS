{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhy/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.16s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# dataset \n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import pyvww\n",
    "mean = [0.4698069, 0.44657433, 0.40738317]\n",
    "std = [0.2762676, 0.27169052, 0.28657043]\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.RandomCrop(36, padding=4),\n",
    "    # transforms.CenterCrop(32),\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "num_classes = 2\n",
    "train_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=\"/home/qhy/data/coco2017/all2017\", \n",
    "                    annFile=\"/home/qhy/data/coco2017/annotations/vww/instances_train.json\",transform=transform_train)\n",
    "val_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=\"/home/qhy/data/coco2017/all2017\", \n",
    "                    annFile=\"/home/qhy/data/coco2017/annotations/vww/instances_val.json\",transform=transform_train)\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(\"/home/qhy/data/vww/train\",transform=transform_train)\n",
    "# val_dataset = datasets.ImageFolder(\"/home/qhy/data/vww/val\",transform=transform_train) \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    sampler=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "\n",
    "def make_layer(stage_num, layer_num, channel_num_in, channel_num_out, op_type,\n",
    "               with_pool,pool_type):\n",
    "    channel_nums_in = [channel_num_in] + [channel_num_out] * (layer_num - 1)\n",
    "    layers = []\n",
    "    if stage_num == 0 :\n",
    "        first_layer_stride = 1\n",
    "    else:\n",
    "        first_layer_stride = 2\n",
    "    if with_pool == True:\n",
    "        if pool_type == \"avgpool\":\n",
    "            layers.append((\"avgpool\", nn.AvgPool2d(2, 2)))\n",
    "        else:\n",
    "            layers.append((\"maxpool\", nn.MaxPool2d(2, 2)))\n",
    "        if op_type == 'vgg':\n",
    "            layers.append((\"stage_{}_0_vgg\".format(stage_num),\n",
    "                           VGGBlock(channel_num_in,\n",
    "                                    channel_num_out,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=1)))\n",
    "            layers += [(\"stage_{}_{}_vgg\".format(stage_num, i),\n",
    "                        VGGBlock(channel_num_out, channel_num_out, 3))\n",
    "                       for i in range(1, layer_num)]\n",
    "        else:\n",
    "            layers.append((\"stage_{}_0_repvgg\".format(stage_num),\n",
    "                           RepVGGBlock(channel_num_in,\n",
    "                                       channel_num_out,\n",
    "                                       kernel_size=3,\n",
    "                                       stride=1,\n",
    "                                       padding=1)))\n",
    "            layers += [(\"stage_{}_{}_repvgg\".format(stage_num, i),\n",
    "                        RepVGGBlock(channel_num_out,\n",
    "                                    channel_num_out,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=1,\n",
    "                                    padding=1)) for i in range(1, layer_num)]\n",
    "\n",
    "    else:\n",
    "        if op_type == 'vgg':\n",
    "            layers.append((\"stage_{}_0_vgg\".format(stage_num),\n",
    "                           VGGBlock(channel_num_in,\n",
    "                                    channel_num_out,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=first_layer_stride)))\n",
    "            layers += [(\"stage_{}_{}_vgg\".format(stage_num, i),\n",
    "                        VGGBlock(channel_num_out, channel_num_out, 3))\n",
    "                       for i in range(1, layer_num)]\n",
    "        else:\n",
    "            layers.append((\"stage_{}_0_repvgg\".format(stage_num),\n",
    "                           RepVGGBlock(channel_num_in,\n",
    "                                       channel_num_out,\n",
    "                                       kernel_size=3,\n",
    "                                       padding=1,\n",
    "                                       stride=first_layer_stride)))\n",
    "            layers += [(\"stage_{}_{}_repvgg\".format(stage_num, i),\n",
    "                        RepVGGBlock(channel_num_out,\n",
    "                                    channel_num_out,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=1,\n",
    "                                    padding=1)) for i in range(1, layer_num)]\n",
    "    return nn.Sequential(OrderedDict(layers))\n",
    "def VGGBlock(in_channels,\n",
    "             out_channels,\n",
    "             kernel_size,\n",
    "             stride=1,\n",
    "             padding=1,\n",
    "             dilation=1,\n",
    "             groups=1,\n",
    "             padding_mode='zeros'):\n",
    "    conv2d = nn.Conv2d(in_channels,\n",
    "                       out_channels,\n",
    "                       kernel_size=kernel_size,\n",
    "                       stride = stride,\n",
    "                       padding=1,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       padding_mode='zeros')\n",
    "    layers = nn.Sequential(\n",
    "        OrderedDict([(\"conv\", conv2d), (\"bn\", nn.BatchNorm2d(out_channels)),\n",
    "                     (\"relu\", nn.ReLU(inplace=True))]))\n",
    "    return layers\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool = False\n",
    "        self.stage_0 = make_layer(0, 1, 3, 64, \"vgg\",\n",
    "               with_pool=False,pool_type=\"None\")\n",
    "        # self.pool = torch.nn.MaxPool2d(2,2)\n",
    "        self.stage_1 = make_layer(1, 1, 64, 16, \"vgg\",\n",
    "               with_pool=False,pool_type=\"None\")\n",
    "        self.stage_2 = make_layer(2, 1, 16, 8, \"vgg\",\n",
    "               with_pool=False,pool_type=\"None\")\n",
    "        self.stage_3 = make_layer(3, 1, 8, 1, \"vgg\",\n",
    "               with_pool=False,pool_type=\"None\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        # self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        \n",
    "        self.linear = nn.Linear(64, 32)\n",
    "        self.linear_2 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        out = self.stage_0(input)\n",
    "        # out = self.pool(out)\n",
    "        out = self.stage_1(out)\n",
    "        # out = self.pool(out)\n",
    "        out = self.stage_2(out)\n",
    "        out = self.stage_3(out)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # out = self.gap(out)\n",
    "        # print(out.shape)\n",
    "        out = self.linear(out.view(out.size(0), -1))\n",
    "        out = self.linear_2(out.view(out.size(0), -1))\n",
    "        \n",
    "        # out = self.classifier(out.view(out.size(0), -1))\n",
    "        return out\n",
    "model = Net(2)\n",
    "input = torch.randn(3,3,64,64)\n",
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExpLR.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.010000 Loss is :0.0012,Train Accuracy is:25.6726%,Test Accuracy is:61.8935%\n",
      "Epoch  1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.009800 Loss is :0.0011,Train Accuracy is:28.5582%,Test Accuracy is:64.2760%\n",
      "Epoch  2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.009604 Loss is :0.0011,Train Accuracy is:29.8287%,Test Accuracy is:67.0431%\n",
      "Epoch  3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.009412 Loss is :0.0010,Train Accuracy is:30.8154%,Test Accuracy is:68.5445%\n",
      "Epoch  4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.009224 Loss is :0.0010,Train Accuracy is:31.3370%,Test Accuracy is:70.3313%\n",
      "Epoch  5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.009039 Loss is :0.0010,Train Accuracy is:31.8490%,Test Accuracy is:70.7036%\n",
      "Epoch  6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008858 Loss is :0.0010,Train Accuracy is:32.1007%,Test Accuracy is:71.2744%\n",
      "Epoch  7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008681 Loss is :0.0010,Train Accuracy is:32.3984%,Test Accuracy is:72.2546%\n",
      "Epoch  8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008508 Loss is :0.0009,Train Accuracy is:32.7446%,Test Accuracy is:72.9123%\n",
      "Epoch  9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008337 Loss is :0.0009,Train Accuracy is:33.0302%,Test Accuracy is:73.1108%\n",
      "Epoch  10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008171 Loss is :0.0009,Train Accuracy is:33.2428%,Test Accuracy is:73.1356%\n",
      "Epoch  11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.008007 Loss is :0.0009,Train Accuracy is:33.4814%,Test Accuracy is:73.5327%\n",
      "Epoch  12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007847 Loss is :0.0009,Train Accuracy is:33.5283%,Test Accuracy is:73.8677%\n",
      "Epoch  13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007690 Loss is :0.0009,Train Accuracy is:33.5882%,Test Accuracy is:74.1903%\n",
      "Epoch  14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007536 Loss is :0.0009,Train Accuracy is:33.8650%,Test Accuracy is:74.4757%\n",
      "Epoch  15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007386 Loss is :0.0009,Train Accuracy is:34.0238%,Test Accuracy is:75.1706%\n",
      "Epoch  16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007238 Loss is :0.0009,Train Accuracy is:34.0950%,Test Accuracy is:75.2451%\n",
      "Epoch  17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.007093 Loss is :0.0009,Train Accuracy is:34.2226%,Test Accuracy is:75.6049%\n",
      "Epoch  18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.006951 Loss is :0.0009,Train Accuracy is:34.2104%,Test Accuracy is:75.8655%\n",
      "Epoch  19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.60it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.006812 Loss is :0.0008,Train Accuracy is:34.3953%,Test Accuracy is:75.5429%\n",
      "Epoch  20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.006676 Loss is :0.0008,Train Accuracy is:34.4942%,Test Accuracy is:75.9524%\n",
      "Epoch  21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 200/451 [01:16<01:36,  2.61it/s]\n",
      "100%|██████████| 63/63 [00:23<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr is :0.006543 Loss is :0.0008,Train Accuracy is:34.4855%,Test Accuracy is:75.8779%\n",
      "Epoch  22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 107/451 [00:40<01:48,  3.18it/s]"
     ]
    }
   ],
   "source": [
    "# 对模型进行训练和参数优化\n",
    "cnn_model = Net(2)\n",
    "cnn_model.cuda()\n",
    "learning_rate = 0.01\n",
    "import tqdm \n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn_model.parameters(),lr=learning_rate)\n",
    "ExpLR = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "\n",
    "n_epochs = 100\n",
    "predict_acc = []\n",
    "train_acc = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    print(\"Epoch  {}/{}\".format(epoch, n_epochs))\n",
    "    num_iter = 0\n",
    "    for data in tqdm.tqdm(train_loader):\n",
    "        num_iter += 1\n",
    "        X_train, y_train = data\n",
    "        X_train, y_train = X_train.cuda(), y_train.cuda()\n",
    "        outputs = cnn_model(X_train)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_correct += torch.sum(pred == y_train.data)\n",
    "        if num_iter > 200:\n",
    "            break\n",
    "    testing_correct = 0.0\n",
    "    for data in tqdm.tqdm(val_loader):\n",
    "        X_test, y_test = data\n",
    "        # X_test, y_test = Variable(X_test), Variable(y_test)\n",
    "        X_test, y_test = X_test.cuda(), y_test.cuda()\n",
    "        outputs = cnn_model(X_test)\n",
    "        _, pred = torch.max(outputs, 1) #返回每一行中最大值的那个元素，且返回其索引\n",
    "        testing_correct += torch.sum(pred == y_test.data)\n",
    "        # print(testing_correct)\n",
    "    print(\"lr is :{:.6f} Loss is :{:.4f},Train Accuracy is:{:.4f}%,Test Accuracy is:{:.4f}%\".format(\n",
    "        ExpLR.get_last_lr()[0],\n",
    "        running_loss / len(train_dataset), 100 * running_correct / len(train_dataset),\n",
    "        100 * testing_correct / len(val_dataset)))\n",
    "    ExpLR.step()\n",
    "    predict_acc.append(100 * testing_correct / len(val_dataset))\n",
    "    train_acc.append(100 * running_correct / len(train_dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1520920080445844e-43"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExpLR.step()\n",
    "ExpLR.get_last_lr()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加linear2之前精度72.\n",
    "# 添加linear2之后精度77.56 50epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c702fa59d8122797944f957dba7be4f979da7d1929b3cf04b128c443ec5b9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
