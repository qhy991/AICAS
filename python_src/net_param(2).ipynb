{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d39024ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f766213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数组中元素拼接组合\n",
    "def array_to_string(array, elem_bit):\n",
    "    val = 0\n",
    "    for i in range(len(array)):\n",
    "        tmp = array[i]\n",
    "        tmp2 = tmp\n",
    "        \n",
    "        if tmp < 0:\n",
    "            tmp2 = 2**(elem_bit) + tmp\n",
    "            \n",
    "        tmp2 = int(tmp2)\n",
    "        tmp3 = tmp2 * 2**(elem_bit*i)\n",
    "        val = val + tmp3\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "792e25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamProcess:\n",
    "    def __init__(self, name, config, w, bias, w_bit, in_bit, out_bit, bias_bit, pe, simd, r_shift, conv_linear=True):\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.w = w\n",
    "        self.bias = bias\n",
    "        self.w_bit = w_bit\n",
    "        self.in_bit = in_bit\n",
    "        self.out_bit = out_bit\n",
    "        self.bias_bit = bias_bit\n",
    "        self.pe = pe\n",
    "        self.simd = simd\n",
    "        self.r_shift = r_shift\n",
    "        self.conv_linear = conv_linear\n",
    "    \n",
    "    # 将矩阵整理成所需的存储样式\n",
    "    # 转化为pe * tiles矩阵\n",
    "    def w_to_hls_array(self, w):\n",
    "        # print(#\"w shape: \", w.shape)\n",
    "        assert w.shape[0] % self.pe == 0, 'out_ch mod pe must 0'\n",
    "        # w 矩阵宽 k*K*in_ch\n",
    "        h = w.shape[1]\n",
    "        # res0 size = out_ch, k*K*in_ch // simd + (0 or 1)\n",
    "        res0 = [[0 for i in range(h // self.simd)] for j in range(w.shape[0])]\n",
    "        for out_ch in range(w.shape[0]):\n",
    "            for i in range(h // self.simd):\n",
    "                arr = w[out_ch][i*self.simd:(i+1)*self.simd]\n",
    "                res0[out_ch][i] = array_to_string(arr, self.w_bit)\n",
    "        \n",
    "        # 处理不够整除部分\n",
    "        if h % self.simd != 0:\n",
    "            print('h mod simd != 0')\n",
    "            for out_ch in range(w.shape[0]):\n",
    "                arr = w[out_ch][h // self.simd * self.simd]\n",
    "                res0[out_ch].append(array_to_string(arr, self.w_bit))\n",
    "                \n",
    "        \n",
    "        tiles = len(res0[0]) * (len(res0) // self.pe)\n",
    "        self.w_tiles = tiles\n",
    "        # print('tiles', tiles)\n",
    "        res = [[0 for i in range(tiles)] for i in range(self.pe)]\n",
    "        \n",
    "        tiles_cnt = 0\n",
    "        for i in range(len(res0) // self.pe):\n",
    "            for j in range(len(res0[0])):\n",
    "                for pe_cnt in range(self.pe):\n",
    "                    res[pe_cnt][tiles_cnt] = res0[i * self.pe + pe_cnt][j]\n",
    "                tiles_cnt += 1\n",
    "        return res\n",
    "    \n",
    "    def bias_to_hls_array(self, bias):\n",
    "        bias = bias.reshape(-1, self.pe)\n",
    "        bias = bias.T\n",
    "        \n",
    "        return bias\n",
    "    \n",
    "    def conv(self):\n",
    "        w = self.w\n",
    "        bias = self.bias\n",
    "        # w是二维矩阵形式\n",
    "        conv_w = w.transpose(0, 2, 3, 1)\n",
    "        # 处理为二维矩阵\n",
    "        conv_w = conv_w.reshape(conv_w.shape[0], -1)\n",
    "        # print(w.shape)\n",
    "        # 先把w处理为每个元素位宽都是simd * w_bit形式\n",
    "        conv_w = self.w_to_hls_array(conv_w)\n",
    "        \n",
    "        bias = self.bias_to_hls_array(bias)\n",
    "        \n",
    "        self.hls_w = conv_w\n",
    "        self.hls_bias = bias\n",
    "        \n",
    "        return conv_w, bias\n",
    "    \n",
    "    def linear(self):\n",
    "        w = self.w\n",
    "        bias = self.bias\n",
    "        # 若上一层是卷积层，需要调整参数位置\n",
    "        if (self.conv_linear == True):\n",
    "            last_conv_shape = self.config[\"last_layer_shape\"]\n",
    "            w = w.reshape(w.shape[0], last_conv_shape[0], last_conv_shape[1], last_conv_shape[2])\n",
    "            w = w.transpose(0, 2, 3, 1)\n",
    "            w = w.reshape(w.shape[0], -1)\n",
    "        w = self.w_to_hls_array(w)\n",
    "        bias = self.bias_to_hls_array(bias)\n",
    "\n",
    "        self.hls_w = w\n",
    "        self.hls_bias = bias\n",
    "\n",
    "        return w, bias\n",
    "    \n",
    "    def w_to_hls_init_str(self, w) -> str:\n",
    "        w_mem_type = \"const ap_uint<\"+str(self.w_bit * self.simd)+\">\"\n",
    "        \n",
    "        res = '//'  + self.name + '_w\\n'\n",
    "        res += '//PEs = %d, SIMD = %d\\n' % (self.pe, self.simd)\n",
    "        res += '//bit = %d\\n' % self.w_bit\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_w')\n",
    "        res += '[%d][%d] = {\\n' % (len(w), len(w[0]))\n",
    "        \n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", w))\n",
    "        res += '};\\n'\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def bias_to_hls_init_str(self, bias) -> str:\n",
    "        bias_bit_width = self.bias_bit\n",
    "        \n",
    "        w_mem_type = \"const ap_int<\"+str(self.bias_bit)+\">\"\n",
    "        \n",
    "        res = '// bias\\n'\n",
    "        res += '//'  + self.name + '_bias\\n'\n",
    "        res += '//w_bit = %d\\n' % bias_bit_width\n",
    "        res += w_mem_type\n",
    "        res += (' ' + self.name + '_bias')\n",
    "        res += '[%d][%d] = {\\n' % (len(bias), len(bias[0]))\n",
    "        \n",
    "        res += \",\\n\".join(map(lambda pe:\"{\\\"\"+(\"\\\", \\\"\".join(map(hex, pe)))+\"\\\"}\", bias))\n",
    "        res += '};\\n'\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def layer_param_to_init_str(self, w, bias) -> str:\n",
    "        res = self.w_to_hls_init_str(w)\n",
    "        res += self.bias_to_hls_init_str(bias)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def add_a_config_str(self, config_name, value) -> str:\n",
    "        res = '#define %s_%s %d \\n' % (self.name.upper(), config_name.upper(), value)\n",
    "        return res\n",
    "\n",
    "    def conv_config_str(self) -> str:\n",
    "        res = '// ' + self.name + '\\n'\n",
    "        res += self.add_a_config_str('K', self.config['k'])\n",
    "        res += self.add_a_config_str('S', self.config['s'])\n",
    "        res += self.add_a_config_str('P', self.config['p'])\n",
    "        res += self.add_a_config_str('IFM_CH', self.config['in_shape'][0])\n",
    "        res += self.add_a_config_str('IFM_ROW', self.config['in_shape'][1])\n",
    "        res += self.add_a_config_str('IFM_COL', self.config['in_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('OFM_CH', self.config['out_shape'][0])\n",
    "        res += self.add_a_config_str('OFM_ROW', self.config['out_shape'][1])\n",
    "        res += self.add_a_config_str('OFM_COL', self.config['out_shape'][2])\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        res += self.add_a_config_str('BIAS_BIT', self.bias_bit)\n",
    "\n",
    "        res += self.add_a_config_str('R_SHIFT', self.r_shift)\n",
    "\n",
    "        res += '\\n'\n",
    "\n",
    "        return res\n",
    "    \n",
    "    def linear_config_str(self) -> str:\n",
    "        # conv1x1\n",
    "        res = '// ' + self.name + '\\n'\n",
    "        res += self.add_a_config_str('K', 1)\n",
    "        res += self.add_a_config_str('S', 1)\n",
    "        res += self.add_a_config_str('P', 0)\n",
    "        res += self.add_a_config_str('IFM_CH', self.config['in_shape'])\n",
    "        res += self.add_a_config_str('IFM_ROW', 1)\n",
    "        res += self.add_a_config_str('IFM_COL', 1)\n",
    "\n",
    "        res += self.add_a_config_str('OFM_CH', self.config['out_shape'])\n",
    "        res += self.add_a_config_str('OFM_ROW', 1)\n",
    "        res += self.add_a_config_str('OFM_COL', 1)\n",
    "\n",
    "        res += self.add_a_config_str('SIMD', self.simd)\n",
    "        res += self.add_a_config_str('PE', self.pe)\n",
    "\n",
    "        res += self.add_a_config_str('IN_BIT', self.in_bit)\n",
    "        res += self.add_a_config_str('OUT_BIT', self.out_bit)\n",
    "        res += self.add_a_config_str('W_BIT', self.w_bit)\n",
    "        res += self.add_a_config_str('BIAS_BIT', self.bias_bit)\n",
    "\n",
    "        res += self.add_a_config_str('R_SHIFT', self.r_shift)\n",
    "\n",
    "        res += '\\n'\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc924f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_analysis(code, pe, simd, r_shift, classify):\n",
    "    config_dic = {}\n",
    "    \n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    #print(channel_num)\n",
    "    layer_num = code[-5:]\n",
    "    #print(layer_num)\n",
    "    map_pool = {0:True, 1:True, 2:False}\n",
    "    pools = [map_pool[key] for key in code[10: 16]]\n",
    "    pools_type = code[10: 16] \n",
    "    #print(pools)\n",
    "    shape_size = [32, 32, 16, 8, 4, 2]\n",
    "    \n",
    "    # initial channel\n",
    "    in_channel = 3\n",
    "    out_channel = int(channel_num[0])\n",
    "    \n",
    "    param_num = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        for j in range(int(layer_num[i])):\n",
    "            name = \"conv_\"+str(i)+\"_\"+str(j)\n",
    "            # initial config\n",
    "            config = {'k':3, 's':1, 'p':1, 'in_shape':(3, 32, 32), 'out_shape':(8, 32, 32)}\n",
    "            \n",
    "            # modify 'in_shape'\n",
    "            config['in_shape'] = (in_channel, shape_size[i], shape_size[i])\n",
    "            \n",
    "            if (j == int(layer_num[i])-1):\n",
    "                if (not pools[i]) :\n",
    "                    # no pooling \n",
    "                    config['s'] = 2\n",
    "                    config['out_shape'] = (out_channel, shape_size[i+1], shape_size[i+1])\n",
    "                    config['simd'] = simd[param_num]\n",
    "                    config['pe'] = pe[param_num]\n",
    "                    config['r_shift'] = r_shift[param_num]\n",
    "                    config_dic[name]=config\n",
    "\n",
    "                else :\n",
    "                    # pooling\n",
    "                    config['s'] = 1\n",
    "                    config['out_shape'] = (out_channel, shape_size[i], shape_size[i])\n",
    "                    config['simd'] = simd[param_num]\n",
    "                    config['pe'] = pe[param_num]\n",
    "                    config['r_shift'] = r_shift[param_num]\n",
    "                    config_dic[name]=config\n",
    "                    \n",
    "                    if(pools_type[i]==0):\n",
    "                        pool_name = \"maxpool_\"+str(i)\n",
    "                        config_dic[pool_name]={'k':2, 's':1, 'p':0}\n",
    "                    elif (pools_type[i]==1):\n",
    "                        pool_name = \"avgpool_\"+str(i)\n",
    "                        config_dic[pool_name]={'k':2, 's':1, 'p':0}\n",
    "\n",
    "                # renew channel\n",
    "                if i < 4 :\n",
    "                    in_channel = out_channel\n",
    "                    out_channel = int(channel_num[i+1])\n",
    "                else :\n",
    "                    in_channel = out_channel\n",
    "                    out_channel = out_channel\n",
    "                \n",
    "                param_num += 1\n",
    "                \n",
    "            else :\n",
    "                config['s'] = 1\n",
    "                config['out_shape'] = (out_channel, shape_size[i], shape_size[i])\n",
    "                config['simd'] = simd[param_num]\n",
    "                config['pe'] = pe[param_num]\n",
    "                config['r_shift'] = r_shift[param_num]\n",
    "                config_dic[name]=config\n",
    "\n",
    "                # renew channel\n",
    "                in_channel = out_channel\n",
    "                out_channel = int(channel_num[i])\n",
    "                \n",
    "                param_num += 1\n",
    "    \n",
    "#     config = {}\n",
    "#     linear_name = \"linear\"\n",
    "#     config['in_shape'] = in_channel*shape_size[-1]*shape_size[-1]\n",
    "#     config['out_shape'] = classify\n",
    "#     config['last_layer_shape'] = (in_channel, shape_size[-1], shape_size[-1])\n",
    "#     config['simd'] = simd[param_num]\n",
    "#     config['pe'] = pe[param_num]\n",
    "#     config['r_shift'] = r_shift[param_num]\n",
    "#     config_dic[linear_name]=config\n",
    "\n",
    "#     param_num += 1\n",
    "            \n",
    "    return config_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9df4dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_param(code, config_dic):\n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    layer_num = code[-5:]\n",
    "    \n",
    "    conv = \"\"\n",
    "    conv_config = \"\"\n",
    "    \n",
    "    # conv layer\n",
    "    for i in range(5):\n",
    "        for j in range(int(layer_num[i])):\n",
    "            name = \"conv_\"+str(i)+\"_\"+str(j)\n",
    "            config = config_dic[name]\n",
    "            \n",
    "            weight_shape = (int(config['out_shape'][0]), int(config['in_shape'][0]), 3, 3)\n",
    "            weight = np.random.randint(-256, 255, size=weight_shape)\n",
    "            #print(weight.shape)\n",
    "            \n",
    "            bias_shape = (int(config['out_shape'][0]))\n",
    "            bias = np.random.randint(-256, 255, size=bias_shape)\n",
    "            \n",
    "            processer = ParamProcess(\n",
    "                name=name, \n",
    "                config=config,\n",
    "                w=weight, bias=bias, \n",
    "                w_bit=8, in_bit=8, out_bit=8, bias_bit=32, \n",
    "                pe=config['pe'], simd=config['simd'], r_shift=config['r_shift'])\n",
    "            \n",
    "            w_str, b_str = processer.conv()\n",
    "            conv_str = processer.layer_param_to_init_str(w_str, b_str)\n",
    "            conv_config_str = processer.conv_config_str()\n",
    "            \n",
    "            conv += conv_str\n",
    "            conv_config += conv_config_str\n",
    "    \n",
    "#     # linear layer\n",
    "#     linear_name = \"linear\"\n",
    "#     config = config_dic[linear_name]\n",
    "#     weight_shape = (int(config['out_shape']), int(config['in_shape']))\n",
    "#     weight = np.random.randint(-256, 255, size=weight_shape)\n",
    "#     #print(weight.shape)\n",
    "            \n",
    "#     bias_shape = (int(config['out_shape']))\n",
    "#     bias = np.random.randint(-256, 255, size=bias_shape)\n",
    "            \n",
    "#     processer = ParamProcess(\n",
    "#         name=linear_name, \n",
    "#         config=config,\n",
    "#         w=weight, bias=bias, \n",
    "#         w_bit=8, in_bit=8, out_bit=8, bias_bit=32, \n",
    "#         pe=config['pe'], simd=config['simd'], r_shift=config['r_shift'], \n",
    "#         conv_linear=True)\n",
    "            \n",
    "#     w_str, b_str = processer.linear()\n",
    "#     fc_str = processer.layer_param_to_init_str(w_str, b_str)\n",
    "#     fc_config_str = processer.linear_config_str()\n",
    "            \n",
    "#     conv += fc_str\n",
    "#     conv_config += fc_config_str\n",
    "    \n",
    "    return conv, conv_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "134e8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardware_inference(code, config_dic):\n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    layer_num = code[-5:]\n",
    "    shape_size = [32,32,16,8,4,2]\n",
    "    \n",
    "    infer_str = \\\n",
    "    \"#include <stdint.h>\\n\"+\\\n",
    "    \"#define AP_INT_MAX_W 4096\\n\"+\\\n",
    "    \"#include <ap_int.h>\\n\"+\\\n",
    "    \"#include <hls_video.h>\\n\"+\\\n",
    "    \"#include \\\"stream_tools.h\\\"\\n\"+\\\n",
    "    \"#include \\\"function.h\\\"\\n\"+\\\n",
    "    \"#include \\\"sliding_window_unit.h\\\"\\n\"+\\\n",
    "    \"#include \\\"matrix_vector_unit.h\\\"\\n\"+\\\n",
    "    \"#include \\\"config.h\\\"\\n\"+\\\n",
    "    \"#include \\\"param.h\\\"\\n\"+\\\n",
    "    \"#include \\\"conv2d.h\\\"\\n\"+\\\n",
    "    \"#include \\\"pool2d.h\\\"\\n\\n\"+\\\n",
    "    \"#define IN_IMAGE_WIDTH 32\\n\"+\\\n",
    "    \"#define IN_IMAGE_HEIGHT 32\\n\\n\"+\\\n",
    "    \"void do_compute(stream<my_ap_axis> & in, stream<my_ap_axis> & out, const unsigned int reps) {\\n\"+\\\n",
    "    \"#pragma HLS DATAFLOW\\n\"+\\\n",
    "    \"    const unsigned int num_per_rep = 32 * 32 * 3 * 8 / 64;\\n\\n\"+\\\n",
    "    \"    hls::stream<ap_uint<64> > in_stream_extract(\\\"in_stream_extract\\\");\\n\"+\\\n",
    "    \"#pragma HLS STREAM variable=in_stream_extract depth=2 dim=1\\n\"+\\\n",
    "    \"    ExtractPixels<64, num_per_rep> (in, in_stream_extract, reps);\\n\\n\"+\\\n",
    "    \"    hls::stream<ap_uint<64 * 3> > in_stream0(\\\"in_stream0\\\");\\n\"+\\\n",
    "    \"#pragma HLS STREAM variable=in_stream0 depth=2 dim=1\\n\"+\\\n",
    "    \"    StreamingDataWidthConverter_Batch<64, 64 * 3, num_per_rep>(in_stream_extract, in_stream0, reps);\\n\\n\"\n",
    "    \n",
    "    net_str = \\\n",
    "    \"void ultra_net(stream<my_ap_axis> & in, stream<my_ap_axis> & out, const unsigned int reps) {\\n\\n\"+\\\n",
    "    \"#pragma HLS INTERFACE axis register both port=out\\n\"+\\\n",
    "    \"#pragma HLS INTERFACE axis register both port=in\\n\"+\\\n",
    "    \"#pragma HLS INTERFACE s_axilite port=reps bundle=control\\n\"+\\\n",
    "    \"#pragma HLS INTERFACE s_axilite port=return bundle=control\\n\\n\"\n",
    "    \n",
    "    first_conv = 0\n",
    "    pre_name = \"in_stream1\"\n",
    "    pre_conv_name = \"\"\n",
    "    for name in config_dic.keys():\n",
    "        if \"conv\" in name :\n",
    "            # first layer\n",
    "            if (first_conv == 0):\n",
    "                infer_str += \\\n",
    "                \"    hls::stream<ap_uint<%s_IN_BIT * %s_IFM_CH> > in_stream1_out(\\\"in_stream1_out\\\");\\n\" % (name.upper(), name.upper())+\\\n",
    "                \"#pragma HLS STREAM variable=in_stream1_out depth=2 dim=1\\n\"+\\\n",
    "                \"StreamingDataWidthConverter_Batch<64 * 3, %s_IN_BIT * %s_IFM_CH, num_per_rep / 3> (in_stream0, in_stream1_out, reps);\\n\\n\" % (name.upper(), name.upper())\n",
    "                first_conv += 1\n",
    "                \n",
    "            # other\n",
    "            infer_str += \\\n",
    "            \"    // %s\\n\" % (name)+\\\n",
    "            \"    hls::stream<ap_uint<%s_OUT_BIT * %s_OFM_CH> > %s_out(\\\"%s_out\\\");\\n\" % (name.upper(), name.upper(), name, name)+\\\n",
    "            \"#pragma HLS STREAM variable=%s_out depth=32 dim=1\\n\\n\" % (name)+\\\n",
    "            \"    conv3x3_bn_act<\\n\" +\\\n",
    "            \"            %s_K,\\n\" % (name.upper())+\\\n",
    "            \"            %s_S,\\n\" % (name.upper())+\\\n",
    "            \"            %s_P,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IFM_ROW,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IFM_COL,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IFM_CH,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IN_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_OFM_CH,\\n\" % (name.upper())+\\\n",
    "            \"            %s_OUT_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_W_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            32,\\n\"+\\\n",
    "            \"            %s_BIAS_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_SIMD,\\n\" % (name.upper())+\\\n",
    "            \"            %s_PE,\\n\" % (name.upper())+\\\n",
    "            \"            %s_R_SHIFT>(\\n\" % (name.upper())+\\\n",
    "            \"        %s_out,\\n\" % (pre_name)+\\\n",
    "            \"        %s_w,\\n\" % (name)+\\\n",
    "            \"        %s_bias,\\n\" % (name)+\\\n",
    "            \"        %s_out,\\n\" % (name)+\\\n",
    "            \"        reps);\\n\\n\" \n",
    "            \n",
    "            net_str += \\\n",
    "            \"#pragma HLS ARRAY_PARTITION variable = %s_w complete dim = 1\\n\" % (name)+\\\n",
    "            \"#pragma HLS ARRAY_PARTITION variable = %s_bias complete dim = 1\\n\\n\" % (name)\n",
    "            \n",
    "            pre_name = name\n",
    "        elif \"maxpool\" in name :\n",
    "            # maxpool\n",
    "            infer_str += \\\n",
    "            \"    // maxpooling\\n\" +\\\n",
    "            \"    hls::stream<ap_uint<%s_OUT_BIT * %s_OFM_CH> > %s_out(\\\"%s_out\\\");\\n\" % (pre_name.upper(), pre_name.upper(), name, name) +\\\n",
    "            \"#pragma HLS STREAM variable=%s_out depth=32 dim=1\\n\" % (name) +\\\n",
    "            \"    max_pool2d< 2,\\n\" +\\\n",
    "            \"            %s_OFM_ROW,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OFM_COL,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OFM_CH,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OUT_BIT>(\\n\" % (pre_name.upper()) +\\\n",
    "            \"        %s_out,\\n\" % (pre_name) +\\\n",
    "            \"        %s_out,\\n\" % (name) +\\\n",
    "            \"        reps);\\n\\n\"\n",
    "            pre_conv_name = pre_name\n",
    "            pre_name = name\n",
    "        elif \"avgpool\" in name :\n",
    "            # avgpool\n",
    "            infer_str += \\\n",
    "            \"    // avgpooling\\n\" +\\\n",
    "            \"    hls::stream<ap_uint<%s_OUT_BIT * %s_OFM_CH> > %s_out(\\\"%s_out\\\");\\n\" % (pre_name.upper(), pre_name.upper(), name, name) +\\\n",
    "            \"#pragma HLS STREAM variable=%s_out depth=32 dim=1\\n\" % (name) +\\\n",
    "            \"    avg_pool2d< 2,\\n\" +\\\n",
    "            \"            %s_OFM_ROW,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OFM_COL,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OFM_CH,\\n\" % (pre_name.upper()) +\\\n",
    "            \"            %s_OUT_BIT>(\\n\" % (pre_name.upper()) +\\\n",
    "            \"        %s_out,\\n\" % (pre_name) +\\\n",
    "            \"        %s_out,\\n\" % (name) +\\\n",
    "            \"        reps);\\n\\n\"\n",
    "            pre_conv_name = pre_name\n",
    "            pre_name = name\n",
    "        elif \"linear\" in name :\n",
    "            # linear(conv1x1)\n",
    "            infer_str += \\\n",
    "            \"    // %s\\n\" % (name)+\\\n",
    "            \"    hls::stream<ap_uint<%s_OUT_BIT * %s_OFM_CH> > %s_out(\\\"%s_out\\\");\\n\" % (name.upper(), name.upper(), name, name)+\\\n",
    "            \"#pragma HLS STREAM variable=%s_out depth=32 dim=1\\n\\n\" % (name)+\\\n",
    "            \"    conv1x1_bn_act<\\n\" +\\\n",
    "            \"            %s_IFM_ROW,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IFM_COL,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IFM_CH,\\n\" % (name.upper())+\\\n",
    "            \"            %s_IN_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_OFM_CH,\\n\" % (name.upper())+\\\n",
    "            \"            %s_OUT_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_W_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            32,\\n\"+\\\n",
    "            \"            %s_BIAS_BIT,\\n\" % (name.upper())+\\\n",
    "            \"            %s_SIMD,\\n\" % (name.upper())+\\\n",
    "            \"            %s_PE,\\n\" % (name.upper())+\\\n",
    "            \"            %s_R_SHIFT>(\\n\" % (name.upper())+\\\n",
    "            \"        %s_out,\\n\" % (pre_name)+\\\n",
    "            \"        %s_w,\\n\" % (name)+\\\n",
    "            \"        %s_bias,\\n\" % (name)+\\\n",
    "            \"        %s_out,\\n\" % (name)+\\\n",
    "            \"        reps);\\n\\n\" \n",
    "            pre_name = name\n",
    "    \n",
    "    if \"conv\" in pre_name:\n",
    "        infer_str += \\\n",
    "        \"    // output\\n\" +\\\n",
    "        \"    hls::stream<ap_uint<64> >  net_out(\\\"net_out\\\");\\n\" +\\\n",
    "        \"#pragma HLS STREAM variable=net_out depth=32 dim=1\\n\" +\\\n",
    "        \"    StreamingDataWidthConverter_Batch<%s_OUT_BIT * %s_OFM_CH, 64, %s_OFM_ROW*%s_OFM_COL> (%s_out, net_out, reps);\\n\\n\" % (pre_name.upper(), pre_name.upper(), pre_name.upper(), pre_name.upper(),name) +\\\n",
    "        \"    AddLast<%s_OFM_ROW*%s_OFM_COL>(net_out, out, reps);\\n\" % (pre_name.upper(), pre_name.upper())+\\\n",
    "        \"}\\n\"\n",
    "    elif \"pool\" in pre_name:\n",
    "        infer_str += \\\n",
    "        \"    // output\\n\" +\\\n",
    "        \"    hls::stream<ap_uint<64> >  net_out(\\\"net_out\\\");\\n\" +\\\n",
    "        \"#pragma HLS STREAM variable=net_out depth=32 dim=1\\n\" +\\\n",
    "        \"    StreamingDataWidthConverter_Batch<%s_OUT_BIT * %s_OFM_CH, 64, %s_OFM_ROW*%s_OFM_COL/4> (%s_out, net_out, reps);\\n\\n\" % (pre_conv_name.upper(), pre_conv_name.upper(), pre_conv_name.upper(), pre_conv_name.upper(),name) +\\\n",
    "        \"    AddLast<%s_OFM_ROW*%s_OFM_COL>(net_out, out, reps);\\n\" % (pre_conv_name.upper(), pre_conv_name.upper())+\\\n",
    "        \"}\\n\"\n",
    "    \n",
    "    net_str += \\\n",
    "    \"    do_compute(in, out, reps);\\n\"+\\\n",
    "    \"}\\n\"\n",
    "    \n",
    "    infer_str += net_str\n",
    "    \n",
    "    return infer_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97c6f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64, 64, 128, 256, 512\n",
    "# 64, 64, 32, 96, 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "824faf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = [0.125, 0.125, 0.125, 0.125, 0.125, \n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 2, 2, 2, \n",
    "#         1, 1, 1, 1, 1]\n",
    "# pe = [4]*5\n",
    "# simd = [3]+[4]*4\n",
    "# r_shift = [9]*10\n",
    "# classify = 10\n",
    "# code = [1.0,1.0,1.0,0.625,0.125,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 0, 2, 2, \n",
    "#         2,4,1,1,1]\n",
    "# pe = [16]*9\n",
    "# simd = [3]+[24]*8\n",
    "# r_shift = [9]*10\n",
    "# classify = 10\n",
    "\n",
    "# code = [1.0,1.0,1.0,1.0,0.125,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 2, 2, 2, \n",
    "#         2,4,4,1,1]\n",
    "# pe = [8]*12\n",
    "# simd = [3]+[4]*5+[8]*6\n",
    "# r_shift = [9]*12\n",
    "# classify = 10\n",
    "\n",
    "# code = [1.0,1.0,1.0,1.0,1.0,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 0, 0, 0, 0, 0, \n",
    "#         2,2,2,2,2]\n",
    "# pe = [16]*10\n",
    "# simd = [3]+[32]*9\n",
    "# r_shift = [9]*10\n",
    "# classify = 10\n",
    "\n",
    "# code = [0.5,1.0,1.0,1.0,0.125,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 2, 2, 2, \n",
    "#         2,1,1,1,1]\n",
    "# pe = [8]*6\n",
    "# simd = [3]+[8]*5\n",
    "# r_shift = [9]*10\n",
    "# classify = 10\n",
    "\n",
    "# code = [0.875,0.75,1.0,1.0,0.125,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 2, 2, 2, \n",
    "#         2,4,1,1,4]\n",
    "# pe = [8]*12\n",
    "# simd = [3]+[12]*5+[24]*6\n",
    "# r_shift = [9]*12\n",
    "# classify = 10\n",
    "# code = [1. ,  0.625, 0.125 ,0.25,  0.125,\n",
    "#         1 ,   1,   0,   1,    0,\n",
    "#         0,   2 ,  0,   1,    2,    2,\n",
    "#         2,    2,    1,    1,    2,  ]\n",
    "# pe =  [16, 16, 4, 4, 8, 2, 4, 4] \n",
    "\n",
    "# simd = [3, 32, 16, 8, 2, 16, 4, 4]\n",
    "# r_shift = [9]*12\n",
    "# classify = 10\n",
    "# code = [1.0,1.0,1.0,1.0,0.125,\n",
    "#         1, 1, 1, 1, 1, \n",
    "#         2, 2, 2, 2, 2, 2, \n",
    "#         1,1,1,1,1]\n",
    "# pe = [32, 32, 64, 128, 32]\n",
    "# simd = [3]+[8]*4\n",
    "# r_shift = [9]*10\n",
    "# classify = 10\n",
    "\n",
    "code = [1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0]\n",
    "pe = [32, 32, 32, 32, 4, 32]\n",
    "simd = [3, 32, 32, 32, 2, 32]\n",
    "r_shift = [9]*10\n",
    "classify = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59485e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = model_analysis(code, pe, simd, r_shift, classify)\n",
    "conv_param, conv_config = config_param(code, config)\n",
    "\n",
    "hls_param_file = open('param.h', 'w')\n",
    "hls_config_file = open('config.h', 'w')\n",
    "\n",
    "hls_param_file.write(conv_param)\n",
    "hls_config_file.write(conv_config)\n",
    "\n",
    "hls_param_file.close()\n",
    "hls_config_file.close()\n",
    "infer_str = hardware_inference(code, config)\n",
    "#print(inference_str)\n",
    "\n",
    "hls_compute_file = open('ultranet.cpp', 'w')\n",
    "\n",
    "hls_compute_file.write(infer_str)\n",
    "\n",
    "hls_compute_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7029d808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3178.0 3712 1.8383494736842103\n"
     ]
    }
   ],
   "source": [
    "bram, dsp, cycle = hw_inference(code, config)\n",
    "print(bram, dsp, cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f5d529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bram_inference(code, config_dic):\n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    layer_num = code[-5:]\n",
    "    shape_size = [32,32,16,8,4,2]\n",
    "    \n",
    "    # initial\n",
    "    bram_num = np.ceil(64/18)\n",
    "\n",
    "    \n",
    "    \n",
    "    first_conv = 0\n",
    "\n",
    "    for name in config_dic.keys():\n",
    "        if \"conv\" in name :\n",
    "            # first layer\n",
    "            if (first_conv == 0):\n",
    "                bram_num += np.ceil(64*config_dic[name]['in_shape'][0]/18)+np.ceil(8*config_dic[name]['in_shape'][0]/18)\n",
    "                first_conv += 1\n",
    "                \n",
    "            # other\n",
    "            # weight mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(config_dic[name]['simd']*8/18)*np.ceil(((config_dic[name]['in_shape'][0]*9)/config_dic[name]['simd'])*(config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # bias mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(8/18)*np.ceil((config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # padding fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # swu fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # conv_out fifo\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "\n",
    "        elif \"maxpool\" in name :\n",
    "            # maxpool\n",
    "            # swu_out\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            # pool_out\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            \n",
    "        elif \"avgpool\" in name :\n",
    "            # avgpool\n",
    "            # swu_out\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            # pool_out\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "\n",
    "        elif \"linear\" in name :\n",
    "            # linear(conv1x1)\n",
    "            # weight mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(config_dic[name]['simd']*8/18)*np.ceil(((config_dic[name]['in_shape'][0]*9)/config_dic[name]['simd'])*(config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # bias mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(8/18)*np.ceil((config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # padding fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # swu fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # conv_out fifo\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            \n",
    "    bram_num += np.ceil(64/18)\n",
    "    \n",
    "    return bram_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de636c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'out_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bram_num \u001b[39m=\u001b[39m bram_inference(code, config)\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(bram_num)\n",
      "Cell \u001b[0;32mIn[37], line 35\u001b[0m, in \u001b[0;36mbram_inference\u001b[0;34m(code, config_dic)\u001b[0m\n\u001b[1;32m     30\u001b[0m     bram_num \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mceil(config_dic[name][\u001b[39m'\u001b[39m\u001b[39mout_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m\u001b[39m/\u001b[39m\u001b[39m18\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmaxpool\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m name :\n\u001b[1;32m     33\u001b[0m     \u001b[39m# maxpool\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39m# swu_out\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     bram_num \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mceil(config_dic[name][\u001b[39m'\u001b[39;49m\u001b[39mout_shape\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m\u001b[39m/\u001b[39m\u001b[39m18\u001b[39m)\n\u001b[1;32m     36\u001b[0m     \u001b[39m# pool_out\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     bram_num \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mceil(config_dic[name][\u001b[39m'\u001b[39m\u001b[39mout_shape\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m\u001b[39m/\u001b[39m\u001b[39m18\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'out_shape'"
     ]
    }
   ],
   "source": [
    "bram_num = bram_inference(code, config)\n",
    "print(bram_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d8189eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw_inference(code, config_dic):\n",
    "    channel_num = np.array(code[:5])*np.array([64, 64, 128, 256, 512])\n",
    "    layer_num = code[-5:]\n",
    "    shape_size = [32,32,16,8,4,2]\n",
    "    \n",
    "    # initial\n",
    "    bram_num = np.ceil(64/18)\n",
    "\n",
    "    dsp_conv = 0\n",
    "    dsp_all = 0\n",
    "\n",
    "    cycle_conv = 0\n",
    "    cycle_all = 0\n",
    "    \n",
    "    first_conv = 0\n",
    "    pre_name = \"\"\n",
    "    for name in config_dic.keys():\n",
    "        if \"conv\" in name :\n",
    "            # first layer\n",
    "            if (first_conv == 0):\n",
    "                bram_num += np.ceil(64*config_dic[name]['in_shape'][0]/18)+np.ceil(8*config_dic[name]['in_shape'][0]/18)\n",
    "                first_conv += 1\n",
    "                \n",
    "            # other\n",
    "            # weight mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(config_dic[name]['simd']*8/18)*np.ceil(((config_dic[name]['in_shape'][0]*9)/config_dic[name]['simd'])*(config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # bias mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(8/18)*np.ceil((config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # padding fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # swu fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # conv_out fifo\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            pre_name = name\n",
    "\n",
    "            if config_dic[name]['simd'] == 3:\n",
    "                dsp_conv = config_dic[name]['pe']*2\n",
    "            elif config_dic[name]['simd'] == 4:\n",
    "                dsp_conv = config_dic[name]['pe']*2\n",
    "            elif config_dic[name]['simd'] == 8:\n",
    "                dsp_conv = config_dic[name]['pe']*5\n",
    "            elif config_dic[name]['simd'] == 12:\n",
    "                dsp_conv = config_dic[name]['pe']*8\n",
    "            elif config_dic[name]['simd'] == 16:\n",
    "                dsp_conv = config_dic[name]['pe']*10\n",
    "            elif config_dic[name]['simd'] == 24:\n",
    "                dsp_conv = config_dic[name]['pe']*15\n",
    "            elif config_dic[name]['simd'] == 32:\n",
    "                dsp_conv = config_dic[name]['pe']*19\n",
    "            \n",
    "            cycle_conv = (config_dic[name]['in_shape'][0]*9)*config_dic[name]['out_shape'][0]*(config_dic[name]['out_shape'][1]*config_dic[name]['out_shape'][2]) / dsp_conv\n",
    "            \n",
    "\n",
    "        elif \"maxpool\" in name :\n",
    "            # maxpool\n",
    "            # swu_out\n",
    "            bram_num += np.ceil(config_dic[pre_name]['out_shape'][0]*8/18)\n",
    "            # pool_out\n",
    "            bram_num += np.ceil(config_dic[pre_name]['out_shape'][0]*8/18)\n",
    "            pre_name = name\n",
    "            \n",
    "        elif \"avgpool\" in name :\n",
    "            # avgpool\n",
    "            # swu_out\n",
    "            bram_num += np.ceil(config_dic[pre_name]['out_shape'][0]*8/18)\n",
    "            # pool_out\n",
    "            bram_num += np.ceil(config_dic[pre_name]['out_shape'][0]*8/18)\n",
    "            pre_name = name\n",
    "\n",
    "        elif \"linear\" in name :\n",
    "            # linear(conv1x1)\n",
    "            # weight mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(config_dic[name]['simd']*8/18)*np.ceil(((config_dic[name]['in_shape'][0]*9)/config_dic[name]['simd'])*(config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # bias mem\n",
    "            bram_num += config_dic[name]['pe']* np.ceil(8/18)*np.ceil((config_dic[name]['out_shape'][0]/config_dic[name]['pe'])/1024)\n",
    "            # padding fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # swu fifo\n",
    "            bram_num += np.ceil(config_dic[name]['in_shape'][0]*8/18)\n",
    "            # conv_out fifo\n",
    "            bram_num += np.ceil(config_dic[name]['out_shape'][0]*8/18)\n",
    "            pre_name = name\n",
    "        \n",
    "        dsp_all += dsp_conv\n",
    "        cycle_all += cycle_conv\n",
    "            \n",
    "    bram_num += np.ceil(64/18)\n",
    "    \n",
    "    cycle_all *= 1e-5\n",
    "    \n",
    "    return bram_num, dsp_all, cycle_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa551d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117.0 1344 1.124352\n"
     ]
    }
   ],
   "source": [
    "bram, dsp, cycle = hw_inference(code, config)\n",
    "print(bram, dsp, cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2055a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c702fa59d8122797944f957dba7be4f979da7d1929b3cf04b128c443ec5b9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
