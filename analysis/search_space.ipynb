{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.34881024\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# the layer number of each stage\n",
    "stage_layer_max = [2, 4, 14, 2]\n",
    "# the channel number of each layer\n",
    "layer = np.array([64, 128, 256, 512])\n",
    "# the descending step of channel \n",
    "step = 8 \n",
    "op = ['repvgg','vgg'] # every stage\n",
    "maxpool = [True,False]\n",
    "ratio = [0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0]\n",
    "def search_space(stage_layer, layer):\n",
    "    sum = 1\n",
    "    for i in stage_layer_max:\n",
    "        sum *= i\n",
    "    for j in layer:\n",
    "        sum *= len(ratio)\n",
    "    return sum*16*16\n",
    "print(search_space(stage_layer_max,layer)/1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练自动生成yaml\n",
    "# loss acc train val\n",
    "# 存test最好的\n",
    "# loss crossentropy\n",
    "# SGD\n",
    "# lr 0.1，0.001（repvgg\n",
    "# weight decay 0.005，0.05（repvgg\n",
    "# 直接量化repvgg， repvgg block 的量化，需要考虑lr和weight decay\n",
    "\n",
    "# 随机生成模型配置，训\n",
    "# 得到小数据集\n",
    "# acc predictor， 是配置 （nas + predictor\n",
    "# 搜索算法 RL EL （chip memory 约束项，要提acc，降latency\n",
    "# 硬件性能 \n",
    "# hardware performance \n",
    "# 硬件结构固定，公式计算硬件性能\n",
    "# few-shot learning\n",
    "# meta-learning\n",
    "# 搜索考虑memory\n",
    "\n",
    "# 1. search space\n",
    "# 2. 重点是predictor\n",
    "# 3. \n",
    "\n",
    "# random genea\n",
    "# 进一步， 搜索对不同硬件都高效的网络\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhy/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhy/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "====================================================================================================\n",
      "|110|1-2-6-3-1|1.0-1.0-0.125-0.875-0.5|vgg-repvgg-repvgg-vgg-vgg|False-False-True-False-False|None-None-avgpool-None-None-maxpool|cifar100|57.18|19.43||\n",
      "|111|1-2-2-2-3|0.75-0.75-0.375-0.25-0.75|vgg-repvgg-vgg-repvgg-vgg|False-True-False-False-True|None-maxpool-None-None-maxpool-avgpool|cifar100|45.76|21.43||\n",
      "|112|1-2-6-5-4|0.75-0.75-0.375-0.5-0.5|vgg-vgg-vgg-repvgg-repvgg|False-True-False-False-True|None-avgpool-None-None-maxpool-None|cifar100|56.73|20.75||\n",
      "|113|1-1-5-5-2|0.875-0.875-0.125-0.125-0.875|repvgg-repvgg-vgg-vgg-repvgg|False-False-False-True-False|None-None-None-maxpool-None-avgpool|cifar100|36.97|20.69||\n",
      "|114|2-3-1-8-3|0.75-0.75-0.625-0.125-0.375|repvgg-repvgg-vgg-repvgg-repvgg|False-False-True-True-True|None-None-maxpool-avgpool-maxpool-None|cifar100|62.6|18.54||\n",
      "|115|1-4-5-1-2|0.875-0.875-0.375-0.875-0.875|repvgg-repvgg-repvgg-repvgg-vgg|False-False-False-True-False|None-None-None-avgpool-None-avgpool|cifar100|68.36|21.69||\n",
      "|116|1-2-6-8-3|0.75-0.75-0.5-0.375-0.625|vgg-repvgg-vgg-vgg-vgg|False-True-False-True-True|None-avgpool-None-maxpool-avgpool-None|cifar100|62.67|21.15||\n",
      "|117|2-1-5-7-2|1.0-1.0-0.25-0.625-0.75|repvgg-repvgg-vgg-repvgg-vgg|False-True-False-False-False|None-maxpool-None-None-None-None|cifar100|101.32|21.84||\n",
      "|118|1-2-1-3-2|0.5-0.5-0.75-0.5-0.25|vgg-vgg-vgg-repvgg-repvgg|False-False-False-False-False|None-None-None-None-None-avgpool|cifar100|32.6|18.1||\n",
      "|119|2-2-1-1-1|0.625-0.625-0.625-1.0-0.125|vgg-vgg-repvgg-repvgg-repvgg|False-False-False-True-True|None-None-None-maxpool-avgpool-maxpool|cifar100|46.1|17.49||\n",
      "====================================================================================================\n",
      "python3 train.py --config ./config/cifar100/110-stage-1_2_6_3_1-ratio-1.0_1.0_0.125_0.875_0.5-op-vgg_repvgg_repvgg_vgg_vgg-pool-False_False_True_False_False_True-pool_type-None_None_avgpool_None_None_maxpool-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/111-stage-1_2_2_2_3-ratio-0.75_0.75_0.375_0.25_0.75-op-vgg_repvgg_vgg_repvgg_vgg-pool-False_True_False_False_True_True-pool_type-None_maxpool_None_None_maxpool_avgpool-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/112-stage-1_2_6_5_4-ratio-0.75_0.75_0.375_0.5_0.5-op-vgg_vgg_vgg_repvgg_repvgg-pool-False_True_False_False_True_False-pool_type-None_avgpool_None_None_maxpool_None-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/113-stage-1_1_5_5_2-ratio-0.875_0.875_0.125_0.125_0.875-op-repvgg_repvgg_vgg_vgg_repvgg-pool-False_False_False_True_False_True-pool_type-None_None_None_maxpool_None_avgpool-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/114-stage-2_3_1_8_3-ratio-0.75_0.75_0.625_0.125_0.375-op-repvgg_repvgg_vgg_repvgg_repvgg-pool-False_False_True_True_True_False-pool_type-None_None_maxpool_avgpool_maxpool_None-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/115-stage-1_4_5_1_2-ratio-0.875_0.875_0.375_0.875_0.875-op-repvgg_repvgg_repvgg_repvgg_vgg-pool-False_False_False_True_False_True-pool_type-None_None_None_avgpool_None_avgpool-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/116-stage-1_2_6_8_3-ratio-0.75_0.75_0.5_0.375_0.625-op-vgg_repvgg_vgg_vgg_vgg-pool-False_True_False_True_True_False-pool_type-None_avgpool_None_maxpool_avgpool_None-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/117-stage-2_1_5_7_2-ratio-1.0_1.0_0.25_0.625_0.75-op-repvgg_repvgg_vgg_repvgg_vgg-pool-False_True_False_False_False_False-pool_type-None_maxpool_None_None_None_None-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/118-stage-1_2_1_3_2-ratio-0.5_0.5_0.75_0.5_0.25-op-vgg_vgg_vgg_repvgg_repvgg-pool-False_False_False_False_False_True-pool_type-None_None_None_None_None_avgpool-cifar100.yaml\n",
      "python3 train.py --config ./config/cifar100/119-stage-2_2_1_1_1-ratio-0.625_0.625_0.625_1.0_0.125-op-vgg_vgg_repvgg_repvgg_repvgg-pool-False_False_False_True_True_True-pool_type-None_None_None_maxpool_avgpool_maxpool-cifar100.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from random import choices \n",
    "def repvgg_model_convert(model, do_copy=True):\n",
    "    if do_copy:\n",
    "        deploy_model = copy.deepcopy(model)\n",
    "    for module in deploy_model.modules():\n",
    "        if hasattr(module, 'switch_to_deploy'):\n",
    "            module.switch_to_deploy()\n",
    "    return deploy_model\n",
    "# the layer number of each stage\n",
    "stage_layer_max = [2, 4, 6, 8, 4]\n",
    "# the channel number of each layer\n",
    "layer_num_max = [64, 64, 128, 256, 512]\n",
    "# the descending step of channel \n",
    "step = 8 \n",
    "op = ['vgg','repvgg'] # every stage\n",
    "pool_types = [True,False]\n",
    "ratio = [0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0]\n",
    "datasets = [\"cifar100\"]\n",
    "pool_type = [\"maxpool\",\"avgpool\"]\n",
    "# operation \n",
    "# dataset = choices(datasets)[0]\n",
    "# class_num = 10 if dataset == \"cifar10\" else 100\n",
    "import yaml\n",
    "import torch\n",
    "import os \n",
    "import collections\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from thop import profile \n",
    "from models import model as M\n",
    "def save_dict_to_yaml(dict_value: dict, save_path: str):\n",
    "    \"\"\"dict保存为yaml\"\"\"\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(yaml.dump(dict_value, allow_unicode=True))\n",
    " \n",
    "def read_yaml_to_dict(yaml_path: str):\n",
    "    with open(yaml_path) as file:\n",
    "        dict_value = yaml.load(file.read(), Loader=yaml.FullLoader)\n",
    "        return dict_value\n",
    "savedirs = []\n",
    "md_fmts = []\n",
    "for n in range(110,120):\n",
    "    config = {}\n",
    "    pool = []\n",
    "    dataset = choices(datasets)[0]\n",
    "    # 随机生成模型\n",
    "    stage_layer = [choices(range(1,stage_layer_max[0]+1))[0],choices(range(1,stage_layer_max[1]+1))[0],choices(range(1,stage_layer_max[2]+1))[0],choices(range(1,stage_layer_max[3]+1))[0],choices(range(1,stage_layer_max[4]+1))[0]]\n",
    "    # stage_layer\n",
    "    ratio_1 = choices(ratio)[0]\n",
    "    stage_ratio = [ratio_1,ratio_1,choices(ratio)[0],choices(ratio)[0],choices(ratio)[0]]\n",
    "    # stage_ratio\n",
    "    with_pool = [False,choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0]]\n",
    "    # with_pool\n",
    "    op_type = [choices(op)[0],choices(op)[0],choices(op)[0],choices(op)[0],choices(op)[0]]\n",
    "    # with_last_pool = choices(pool_types)[0]\n",
    "    \n",
    "        \n",
    "    for pool_or_not in with_pool:\n",
    "        if pool_or_not:\n",
    "             pool.append(choices(pool_type)[0])\n",
    "        else:\n",
    "            pool.append(None)\n",
    "    # if with_last_pool:\n",
    "    #     pool.append(choices(pool_type)[0])\n",
    "    # else:\n",
    "    #     pool.append(None)\n",
    "    dir = str(n)+'-stage-' + str(stage_layer[0]) + '_' + str(stage_layer[1]) + '_' + str(stage_layer[2]) + '_' + str(stage_layer[3]) + '_' + str(stage_layer[4]) + '-ratio-' \\\n",
    "    + str(stage_ratio[0]) + '_' + str(stage_ratio[1]) + '_' + str(stage_ratio[2]) + '_' + str(stage_ratio[3]) + '_' + str(stage_ratio[4]) +  \\\n",
    "        '-op-' + str(op_type[0]) + '_' + str(op_type[1]) + '_' + str(op_type[2]) + '_' + str(op_type[3]) + '_' + str(op_type[4]) + '-pool-' + \\\n",
    "            str(with_pool[0]) + '_' + str(with_pool[1]) + '_' + str(with_pool[2]) + '_' + str(with_pool[3]) + '_' + str(with_pool[4]) + '_' + str(with_pool[5]) + '-pool_type-'+\\\n",
    "                str(pool[0]) + '_' + str(pool[1]) + '_' + str(pool[2]) + '_' + str(pool[3]) + '_' + str(pool[4]) + '_' + str(pool[5]) + '-' + dataset\n",
    "    \n",
    "    config['dataset'] = dataset\n",
    "    config['model'] = {'stage_layer':stage_layer,'stage_ratio': stage_ratio ,'with_pool':with_pool,\"pool_type\":pool,'op_type':op_type,\"layer_num_max\":layer_num_max}\n",
    "    config['train'] = {'start_epoch': 0, \"epochs\": 100, \"warmup_epochs\": 0, \"warmup_lr\": 1.0e-2, \n",
    "                    \"lr_scheduler\":{\"min_lr\":1.0e-5,\"decay_epochs\":30,\"decay_rate\":0.1},\"batch_size\":256,\"loss\":\"crossentropy\",\"workers\":4,\n",
    "                    \"optimizer\":{\"name\":\"SGD\",\"base_lr\":0.5,\"repvgg_lr\":0.5,\"momentum\":0.9,\"eps\":1.0e-8,\"betas\":[0.9,0.999],\"weight_decay_param\":{\"base_decay\":5e-4,\"repvgg_decay\":1e-4,\"echo\":False}},\n",
    "                    \"label_smoothing\":0.1,\"clip_grad\":0.0,\"ema_alpha\":0.0,\"ema_update_period\":8,\"use_l2_norm\":True,\n",
    "                    \"no_weight_decay\": [\"rbr_dense\",\"rbr_1x1\"]}\n",
    "    config['val'] = {\"batch_size\":128,\"workers\":4} \n",
    "    if dataset == \"cifar100\":\n",
    "        save_path = os.path.join(\"../config/cifar100\",dir+'.yaml')\n",
    "        config['output'] = {\"print_freq\":100,\"epoch_print_freq\":1,\"save_freq\":20,\n",
    "                        \"dir\": os.path.join(\"./log/cifar100\",dir), \"name\": str(n)}\n",
    "    else:\n",
    "        save_path = os.path.join(\"../config/cifar10\",dir+'.yaml')\n",
    "        config['output'] = {\"print_freq\":100,\"epoch_print_freq\":1,\"save_freq\":20,\n",
    "                        \"dir\": os.path.join(\"./log/cifar10\",dir), \"name\": str(n)}\n",
    "    model = M.Net(config, 10)\n",
    "    model = repvgg_model_convert(model)\n",
    "    input = torch.randn(1, 3, 32, 32)\n",
    "    flops,params = profile(model, inputs=(input, ))\n",
    "    md_fmt = \"|\"+ str(n)+'|' + str(stage_layer[0]) + '-' + str(stage_layer[1]) + '-' + str(stage_layer[2]) + '-' + str(stage_layer[3]) + '-' + str(stage_layer[4]) + '|'\\\n",
    "        + str(stage_ratio[0]) + '-' + str(stage_ratio[1]) + '-' + str(stage_ratio[2]) + '-' + str(stage_ratio[3]) + '-' + str(stage_ratio[4]) + \\\n",
    "            '|' + str(op_type[0]) + '-' + str(op_type[1]) + '-' + str(op_type[2]) + '-' + str(op_type[3]) + '-' + str(op_type[4]) + '|' + \\\n",
    "                str(with_pool[0]) + '-' + str(with_pool[1]) + '-' + str(with_pool[2]) + '-' + str(with_pool[3]) + '-' + str(with_pool[4]) + '|' +\\\n",
    "                str(pool[0]) + '-' + str(pool[1]) + '-' + str(pool[2]) + '-' + str(pool[3]) + '-' + str(pool[4]) + '-' + str(pool[5]) + '|' + dataset+ \"|\" + str(round(flops/1e6,2))+\"|\"+str(round(params/1e6,2))+\"|\"+\"|\"\n",
    "    md_fmts.append(md_fmt)\n",
    "    savedirs.append(save_path.replace(\"..\",\".\"))\n",
    "    save_dict_to_yaml(config,save_path)\n",
    "\n",
    "print(\"=\"*100)\n",
    "for md in md_fmts:\n",
    "    print(md)\n",
    "print(\"=\"*100)\n",
    "for savedir in savedirs:\n",
    "    print(\"python3 train.py --config \" + savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "import yaml\n",
    "sys.path.append(\"..\")\n",
    "from thop import profile \n",
    "from models import model as M\n",
    "config_path = \"/home/qhy/Reserach/AICAS/config/914-stage-1_3_2_5_1-ratio-1.0_1.0_0.25_0.375_0.75-op-vgg_vgg_vgg_repvgg_repvgg-pool-False_True_False_True_True_False-pool_type-None_avgpool_None_avgpool_maxpool_None-cifar10.yaml\"\n",
    "config = EasyDict(yaml.full_load(open(config_path)))\n",
    "model = M.Net(config, 10)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c702fa59d8122797944f957dba7be4f979da7d1929b3cf04b128c443ec5b9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
