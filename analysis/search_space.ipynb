{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.539607552\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# the layer number of each stage\n",
    "stage_layer_max = [2, 4, 6, 8, 4]\n",
    "# the channel number of each layer\n",
    "layer = np.array([64, 64, 128, 256, 512])\n",
    "# the descending step of channel \n",
    "step = 8 \n",
    "op = ['repvgg','vgg'] # every stage\n",
    "maxpool = [True,False]\n",
    "ratio = [0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0]\n",
    "def search_space(stage_layer, layer):\n",
    "    sum = 1\n",
    "    for i in stage_layer_max:\n",
    "        sum *= i\n",
    "    for j in layer:\n",
    "        sum *= len(ratio)\n",
    "    return sum*32*32\n",
    "print(search_space(stage_layer_max,layer)/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练自动生成yaml\n",
    "# loss acc train val\n",
    "# 存test最好的\n",
    "# loss crossentropy\n",
    "# SGD\n",
    "# lr 0.1，0.001（repvgg\n",
    "# weight decay 0.005，0.05（repvgg\n",
    "# 直接量化repvgg， repvgg block 的量化，需要考虑lr和weight decay\n",
    "\n",
    "# 随机生成模型配置，训\n",
    "# 得到小数据集\n",
    "# acc predictor， 是配置 （nas + predictor\n",
    "# 搜索算法 RL EL （chip memory 约束项，要提acc，降latency\n",
    "# 硬件性能 \n",
    "# hardware performance \n",
    "# 硬件结构固定，公式计算硬件性能\n",
    "# few-shot learning\n",
    "# meta-learning\n",
    "# 搜索考虑memory\n",
    "\n",
    "# 1. search space\n",
    "# 2. 重点是predictor\n",
    "# 3. \n",
    "\n",
    "# random genea\n",
    "# 进一步， 搜索对不同硬件都高效的网络\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qhy/anaconda3/envs/torch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "====================================================================================================\n",
      "|391|2-3-4-5-3|1.0-1.0-1.0-1.0-1.0|repvgg-repvgg-repvgg-repvgg-repvgg|False-False-False-False-False|None-None-None-None-None-None|cifar100|185.84|28.14||\n",
      "====================================================================================================\n",
      "python3 train.py --config ./config/cifar100/391-stage-2_3_4_5_3-ratio-1.0_1.0_1.0_1.0_1.0-op-repvgg_repvgg_repvgg_repvgg_repvgg-pool-False_False_False_False_False_False-pool_type-None_None_None_None_None_None-cifar100.yaml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from random import choices \n",
    "def repvgg_model_convert(model, do_copy=True):\n",
    "    if do_copy:\n",
    "        deploy_model = copy.deepcopy(model)\n",
    "    for module in deploy_model.modules():\n",
    "        if hasattr(module, 'switch_to_deploy'):\n",
    "            module.switch_to_deploy()\n",
    "    return deploy_model\n",
    "# the layer number of each stage\n",
    "stage_layer_max = [2, 3, 4, 5, 3] #[2, 4, 6, 8, 4]\n",
    "# the channel number of each layer\n",
    "layer_num_max = [64, 64, 128, 256, 512]\n",
    "# the descending step of channel \n",
    "step = 8 \n",
    "op = ['vgg','repvgg'] # every stage\n",
    "pool_types = [True,False]\n",
    "ratio = [ 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0]#0.125, 0.25, 0.375, 0.5,\n",
    "datasets = [\"vww\"]\n",
    "pool_type = [\"maxpool\",\"avgpool\"]\n",
    "# operation \n",
    "# dataset = choices(datasets)[0]\n",
    "# class_num = 10 if dataset == \"cifar10\" else 100\n",
    "import yaml\n",
    "import torch\n",
    "import os \n",
    "import collections\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from thop import profile \n",
    "from models import model as M\n",
    "def save_dict_to_yaml(dict_value: dict, save_path: str):\n",
    "    \"\"\"dict保存为yaml\"\"\"\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(yaml.dump(dict_value, allow_unicode=True))\n",
    " \n",
    "def read_yaml_to_dict(yaml_path: str):\n",
    "    with open(yaml_path) as file:\n",
    "        dict_value = yaml.load(file.read(), Loader=yaml.FullLoader)\n",
    "        return dict_value\n",
    "savedirs = []\n",
    "md_fmts = []\n",
    "for n in range(0,10):\n",
    "    config = {}\n",
    "    pool = []\n",
    "    dataset = choices(datasets)[0]\n",
    "    # 随机生成模型\n",
    "    stage_layer =  [choices(range(1,stage_layer_max[0]+1))[0],choices(range(1,stage_layer_max[1]+1))[0],choices(range(1,stage_layer_max[2]+1))[0],choices(range(1,stage_layer_max[3]+1))[0],choices(range(1,stage_layer_max[4]+1))[0]]\n",
    "    # stage_layer\n",
    "    ratio_1 = choices(ratio)[0]\n",
    "    stage_ratio = [ratio_1,ratio_1,choices(ratio)[0],choices(ratio)[0],choices(ratio)[0]]\n",
    "    # stage_ratio\n",
    "    with_pool = [False,choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0],choices(pool_types)[0]]\n",
    "    # with_pool\n",
    "    op_type = [choices(op)[0],choices(op)[0],choices(op)[0],choices(op)[0],choices(op)[0]]\n",
    "    # with_last_pool = choices(pool_types)[0]\n",
    "    \n",
    "        \n",
    "    for pool_or_not in with_pool:\n",
    "        if pool_or_not:\n",
    "             pool.append(choices(pool_type)[0])\n",
    "        else:\n",
    "            pool.append(None)\n",
    "    # if with_last_pool:\n",
    "    #     pool.append(choices(pool_type)[0])\n",
    "    # else:\n",
    "    #     pool.append(None)\n",
    "    dir = str(n)+'-stage-' + str(stage_layer[0]) + '_' + str(stage_layer[1]) + '_' + str(stage_layer[2]) + '_' + str(stage_layer[3]) + '_' + str(stage_layer[4]) + '-ratio-' \\\n",
    "    + str(stage_ratio[0]) + '_' + str(stage_ratio[1]) + '_' + str(stage_ratio[2]) + '_' + str(stage_ratio[3]) + '_' + str(stage_ratio[4]) +  \\\n",
    "        '-op-' + str(op_type[0]) + '_' + str(op_type[1]) + '_' + str(op_type[2]) + '_' + str(op_type[3]) + '_' + str(op_type[4]) + '-pool-' + \\\n",
    "            str(with_pool[0]) + '_' + str(with_pool[1]) + '_' + str(with_pool[2]) + '_' + str(with_pool[3]) + '_' + str(with_pool[4]) + '_' + str(with_pool[5]) + '-pool_type-'+\\\n",
    "                str(pool[0]) + '_' + str(pool[1]) + '_' + str(pool[2]) + '_' + str(pool[3]) + '_' + str(pool[4]) + '_' + str(pool[5]) + '-' + dataset\n",
    "    \n",
    "    config['dataset'] = dataset\n",
    "    config['model'] = {'stage_layer':stage_layer,'stage_ratio': stage_ratio ,'with_pool':with_pool,\"pool_type\":pool,'op_type':op_type,\"layer_num_max\":layer_num_max}\n",
    "    config['train'] = {'start_epoch': 0, \"epochs\": 100, \"warmup_epochs\": 0, \"warmup_lr\": 1.0e-2, \n",
    "                    \"lr_scheduler\":{\"min_lr\":1.0e-6,\"decay_epochs\":30,\"decay_rate\":0.1},\"batch_size\":256,\"loss\":\"crossentropy\",\"workers\":4,\n",
    "                    \"optimizer\":{\"name\":\"SGD\",\"base_lr\":0.35,\"repvgg_lr\":0.3,\"momentum\":0.9,\"eps\":1.0e-8,\"betas\":[0.9,0.999],\"weight_decay_param\":{\"base_decay\":5e-4,\"repvgg_decay\":5e-4,\"echo\":False}},\n",
    "                    \"label_smoothing\":0.1,\"clip_grad\":0.0,\"ema_alpha\":0.0,\"ema_update_period\":8,\"use_l2_norm\":True,\n",
    "                    \"no_weight_decay\": [\"rbr_dense\",\"rbr_1x1\"]}\n",
    "    config['val'] = {\"batch_size\":128,\"workers\":4} \n",
    "    if dataset == \"cifar100\":\n",
    "        input = torch.randn(1, 3, 32, 32)\n",
    "        save_path = os.path.join(\"../config/cifar100\",dir+'.yaml')\n",
    "        config['output'] = {\"print_freq\":100,\"epoch_print_freq\":1,\"save_freq\":20,\n",
    "                        \"dir\": os.path.join(\"./log/cifar100\",dir), \"name\": str(n)}\n",
    "    elif dataset == \"cifar10\":\n",
    "        input = torch.randn(1, 3, 32, 32)\n",
    "        save_path = os.path.join(\"../config/cifar10\",dir+'.yaml')\n",
    "        config['output'] = {\"print_freq\":100,\"epoch_print_freq\":1,\"save_freq\":20,\n",
    "                        \"dir\": os.path.join(\"./log/cifar10\",dir), \"name\": str(n)}\n",
    "    elif dataset == \"vww\":\n",
    "        input = torch.randn(1, 3, 128, 128)\n",
    "        save_path = os.path.join(\"../config/vww\",dir+'.yaml')\n",
    "        config['output'] = {\"print_freq\":100,\"epoch_print_freq\":1,\"save_freq\":20,\n",
    "                        \"dir\": os.path.join(\"./log/vww\",dir), \"name\": str(n)}\n",
    "    model = M.Net(config, 10)\n",
    "    model = repvgg_model_convert(model)\n",
    "    flops,params = profile(model, inputs=(input, ))\n",
    "    md_fmt = \"|\"+ str(n)+'|' + str(stage_layer[0]) + '-' + str(stage_layer[1]) + '-' + str(stage_layer[2]) + '-' + str(stage_layer[3]) + '-' + str(stage_layer[4]) + '|'\\\n",
    "        + str(stage_ratio[0]) + '-' + str(stage_ratio[1]) + '-' + str(stage_ratio[2]) + '-' + str(stage_ratio[3]) + '-' + str(stage_ratio[4]) + \\\n",
    "            '|' + str(op_type[0]) + '-' + str(op_type[1]) + '-' + str(op_type[2]) + '-' + str(op_type[3]) + '-' + str(op_type[4]) + '|' + \\\n",
    "                str(with_pool[0]) + '-' + str(with_pool[1]) + '-' + str(with_pool[2]) + '-' + str(with_pool[3]) + '-' + str(with_pool[4]) + '|' +\\\n",
    "                str(pool[0]) + '-' + str(pool[1]) + '-' + str(pool[2]) + '-' + str(pool[3]) + '-' + str(pool[4]) + '-' + str(pool[5]) + '|' + dataset+ \"|\" + str(round(flops/1e6,2))+\"|\"+str(round(params/1e6,2))+\"|\"+\"|\"\n",
    "    md_fmts.append(md_fmt)\n",
    "    savedirs.append(save_path.replace(\"..\",\".\"))\n",
    "    save_dict_to_yaml(config,save_path)\n",
    "\n",
    "print(\"=\"*100)\n",
    "for md in md_fmts:\n",
    "    print(md)\n",
    "print(\"=\"*100)\n",
    "for savedir in savedirs:\n",
    "    print(\"python3 train.py --config \" + savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_avgpool() for <class 'torch.nn.modules.pooling.AvgPool2d'>.\n",
      "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "172.287488 28.149514\n"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict\n",
    "import yaml\n",
    "sys.path.append(\"..\")\n",
    "from thop import profile \n",
    "from models import model as M\n",
    "config_path = \"/home/qhy/Reserach/AICAS/config/cifar100/benchmark-vgg11-stage-1_1_2_2_2-ratio-1.0_1.0_1.0_1.0_1.0-op-vgg_vgg_vgg_vgg_vgg-max-False_True_True_True_True-cifar100.yaml\"\n",
    "config = EasyDict(yaml.full_load(open(config_path)))\n",
    "model = M.Net(config, 10)\n",
    "# model\n",
    "input = torch.randn(1, 3, 32, 32)\n",
    "flops,params = profile(model, inputs=(input, ))\n",
    "print(flops/1e6,params/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46428571, 0.73181818, 0.13151316, 0.30924812])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "all  = np.array([280,220,106400,53200])\n",
    "a = np.array([130,161,13993,16452])\n",
    "a/all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112.64399999999999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "280*0.4023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4107142857142857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "115/280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177.474"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8067*220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045454545454546"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "177/220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c702fa59d8122797944f957dba7be4f979da7d1929b3cf04b128c443ec5b9bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
